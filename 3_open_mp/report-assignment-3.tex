\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[a4paper,
            bindingoffset=0.2in,
            left=1in,
            right=1in,
            top=1in,
            bottom=1in,
            footskip=.25in]{geometry}

%###############################################################################

%\input{~/layout/global_layout}


%###############################################################################

% packages begin

\usepackage[
  backend=biber,
  sortcites=true,
  style=alphabetic,
  eprint=true,
  backref=true
]{biblatex}
\addbibresource{bibliographie.bib}
\usepackage[acronym]{glossaries}

\usepackage{euscript}[mathcal]
% e.g. \mathcal{A} for fancy letters in mathmode
\usepackage{amsmath,amssymb,amstext,amsthm}

\usepackage{mdframed}
\newmdtheoremenv[nobreak=true]{problem}{Problem}[subsection]
\newmdtheoremenv[nobreak=true]{claim}{Claim}[subsection]
\newtheorem{definition}{Definition}[subsection]
\newtheorem{lemma}{Lemma}[claim]
\newtheorem{plemma}{Lemma}[problem]

\usepackage{mathtools}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\usepackage{enumerate}
\usepackage[pdftex]{graphicx}
\usepackage{subcaption}
% 'draft' für schnelleres rendern mitübergeben -> [pdftex, draft]
% dadruch wird nicht das bild mitgerendered, sondern nur ein kasten mit bildname -> schont ressourcen

\usepackage{hyperref}

\usepackage{tikz}
\usetikzlibrary{arrows,automata,matrix,positioning,shapes}

% for adding non-formatted text to include source-code
\usepackage{listings}
\lstset{language=Python,basicstyle=\footnotesize}
% z.B.:
% \lstinputlisting{source_filename.py}
% \lstinputlisting[lanugage=Python, firstline=37, lastline=45]{source_filename.py}
%
% oder
%
% \begin{lstlisting}[frame=single]
% CODE HERE
%\end{lstlisting}
\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage{wasysym}

\usepackage{titling}
\usepackage{titlesec}
\usepackage[nocheck]{fancyhdr}
\usepackage{lastpage}

\usepackage{kantlipsum}
\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}

\usepackage{svg}

% packages end
%###############################################################################

\pretitle{% add some rules
  \begin{center}
    \LARGE\bfseries
} %, make the fonts bigger, make the title (only) bold
\posttitle{%
  \end{center}%
  %\vskip .75em plus .25em minus .25em% increase the vertical spacing a bit, make this particular glue stretchier
}
\predate{%
  \begin{center}
    \normalsize
}
\postdate{%
  \end{center}%
}

\titleformat*{\section}{\Large\bfseries}
\titleformat*{\subsection}{\large\bfseries}
\titleformat*{\subsubsection}{\normalsize\bfseries}

\titleformat*{\paragraph}{\Large\bfseries}
\titleformat*{\subparagraph}{\large\bfseries}

%###############################################################################

\pagestyle{fancy}
\fancyhf{}
% l=left, c=center, r=right; e=even_pagenumber, o=odd_pagenumber; h=header, f=footer
% example: [lh] -> left header, [lof,ref] -> fotter left when odd, right when even
%\fancyhf[lh]{}
%\fancyhf[ch]{}
%\fancyhf[rh]{}
%\fancyhf[lf]{}
\fancyhf[cf]{\footnotesize Page \thepage\ of \pageref*{LastPage}}
%\fancyhf[rf]{}
\renewcommand{\headrule}{} % removes horizontal header line

% Fotter options for first page

\fancypagestyle{firstpagestyle}{
  \renewcommand{\thedate}{\textmd{}} % removes horizontal header line
  \fancyhf{}
  \fancyhf[lh]{\ttfamily M.Sc. Computer Science\\KTH Royal Institute of Technology}
  \fancyhf[rh]{\ttfamily Period 4\\\today}
  \fancyfoot[C]{\footnotesize Page \thepage\ of \pageref*{LastPage}}
  \renewcommand{\headrule}{} % removes horizontal header line
}
%###############################################################################

\newcommand\extrafootertext[1]{%
    \bgroup
    \renewcommand\thefootnote{\fnsymbol{footnote}}%
    \renewcommand\thempfootnote{\fnsymbol{mpfootnote}}%
    \footnotetext[0]{#1}%
    \egroup
}

%###############################################################################

\title{
  \normalsize{DD2356 VT25 Methods in}\\
  \normalsize{High Performance Computing}\\
  \large{Assignment 3}
}
\author{
  \small Rishi Vijayvargiya\textsuperscript{\textdagger}\\[-0.75ex]
%  \footnotesize\texttt{MN: }\\[-1ex]
  \scriptsize\texttt{rishiv@kth.se}
  \and
  \small Paul Mayer\textsuperscript{\textdagger}\\[-0.75ex]
%  \footnotesize\texttt{MN: }\\[-1ex]
  \scriptsize\texttt{pmayer@kth.se}
  \and
  \small Lennart Herud \textsuperscript{\textdagger}\\[-0.75ex]
%  \footnotesize\texttt{MN: }\\[-1ex]
  \scriptsize\texttt{herud@kth.se}
}
\date{}

%###############################################################################
% define Commands

\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\I}{\mathbb{I}}

\newcommand{\E}{\mathbb{E}}
\newcommand{\Prob}{\mathbb{P}}

\renewcommand{\epsilon}{\varepsilon}

%###############################################################################
\makeatletter
\renewcommand*{\@fnsymbol}[1]{\ensuremath{\ifcase#1\or \dagger\or \ddagger\or
   \mathsection\or \mathparagraph\or \|\or **\or \dagger\dagger
   \or \ddagger\ddagger \else\@ctrerr\fi}}
\makeatother
%###############################################################################

\begin{document}
\maketitle
\extrafootertext{\textsuperscript{\textdagger}Authors made equal contribution to the project}
\thispagestyle{firstpagestyle}

\listoftodos
\vspace{1em}

% content begin
%

\section*{Prefix}
The code for our project can be found at this location: \url{}. 

\tableofcontents
\newpage

\todo[inline]{Check headers}

\section{Exercise 1 - OpenMP Hello World}
\subsection{Question 1 - Write an OpenMP C code with each thread printing Hello World from Thread X! where X is the thread ID.}
We wrote the c code using the lecture material. The code is attachted in the GitHub repository.
The output looks as follows (exercise1/output.txt):
Hello World from Thread 0! \n
Hello World from Thread 2! \n
Hello World from Thread 1! \n
Hello World from Thread 3! \n


\subsection{Question 2 - How do you compile the code? Which compiler and flags have you used?}
We compile the code using \verb|gcc| compiler. 
The code is compiled using the \verb|-fopenmp| flag to utilize \verb|OpenMP|. The full command is: 
$ srun -n 1 gcc -fopenmp a3/ex1/hello_world.c -o a3/ex1/hello_world.out$
We attached the slurmfile to run the code on \verb|Dardel| in the repo (\verb|ex1.slurm|).

\subsection{Question 3 - Use what you've learned from hwloc/numactl to discover how many cores your job is allocated with. }
The hwloc output is attached in the figure below.
\begin{figure}
  \includesvg[width=\textwidth]{img/ex1/topology.svg}
  \label{ex1topology}
\end{figure}
We can observe that four virtual cores are being utilized on two physical cores. We can see the 4 specified (virtual) CPU cores from our 
jobscript in the figure.

\subsection{Question 4 - How do you run the OpenMP code on Dardel? What flags did you set?}
As stated in question 2, we use the \verb|-fopenmp| flag for the \verb|gcc| compiler to utilize \verb|OpenMP| on \verb|Dardel|.
To run the compiled binary, we use \verb|srun -n 1 a3/ex1/hello_world.out > a3/ex1/output.txt| without setting additional flags.

\subsection{Question 5 - How is the number of threads compared to the number of cores your job is assigned to?}
We assigned 4 virtual CPU cores in our jobscript. As shown in \ref{ex1topology} we can see that the number of threads resembles the number of virtual cores, which is $2 * physical cores$. Running on less cores is possible either, 
the threads will then be executed in a Multithreading manner on the fewer cores, making use of stalls or I/O operations of other threads to use the available ressources as efficiently as possible. However if the number of logical cores
is fewer than the number of threads spawned, we receive a warning indicating that the number of threads is greater than the number of cores to run the program on, but the code still executes.


\section{Exercise 5 - Parallelizing a Shallow Water Simulation}
\subsection{1. Parallelize the loops}
We parallelize the loops given the \verb|#pragma omp parallel for collapse(2)| pragma. 
We implement the different scheduling strategies in the slurm file with is attached to the repository (ex5.slurm).
The timing of the \verb|compute()| method is measured using \verb|omp_get_wtime()|.
The code is run on the cluster using a jobarray in the slurmfile, where we iterate through the permuations.

\subsection{2. Evaluate Performance}
All the data can be found in the repo (\href{https://github.com/paulmyr/DD2356-MethodsHPC/tree/master/3_open_mp/exercise5/data}{Dataset directory}).
We evaluate based on scheduling strategy, gridsize ($N$) and threadcount ($threads$).

For our static scheduling, we observe the fastest exectution for a chunksize of $ 1000 $ for $64 threads$ and a gridsize $N=500$ with $0.040567 s$.
The results (df_static.csv) display the six fastest calculations for $64 threads$ and $N=500$, which are surprisingly faster than a higher threadcount for the same gridsize.

For the dynamic scheduling, we assume even better results since the computational load could theoretically be better distributed. 
We observe the fastest exectution for a chunksize of $ 200 $ for $64 threads$ and a gridsize $N=500$ with $0.041169 s$.
The results (df_dynamic.csv) display the four fastest calculations for $64 threads$ and $N=500$, which are interestingly again faster than a higher threadcount for the same gridsize.
Interestingly the dynamic scheduling is slower than the static scheduling.

For the guided scheduling (df_guided.csv), we observe the following results. The fastest exectution time ($0.040684 s$) is archieved for $64 threads$ and a gridsize $N=500$ for a chunksize of $100$.
Again the $64 threads$ are superior to other threadcounts.

We compare the gridsizes and threads for static scheduling with a chunksize of $1000$:
When looking at different gridsizes we observe:
Time,Grid size,Schedule,Threads,Id
0.040567,500,"static,1000",64,22
0.124492,1000,"static,1000",64,46
0.445595,2000,"static,1000",64,70
3.171261,4000,"static,1000",64,94
14.403611,8000,"static,1000",64,118

Unsurprisingly with a larger gridsize the runtime increases for constant parameters.

When looking at different threadsizes we observe:
Time,Grid size,Schedule,Threads,Write output id, Speedup
1.45063,500,"static,1000",1,20,1.0
0.051778,500,"static,1000",32,21,28.01633898566959
0.040567,500,"static,1000",64,22,35.75886804545567
0.067249,500,"static,1000",128,23,21.57102707846957

Interestingly after 64 threads, the speedup decreases again, which we assume to be due to overhead of creating and managing a higher number of thread (such as scheduling, spawning, etc).

\subsection{3. Visualize the output}
The figure below shows the output for a gridsize of $N=500$ calculated using $32 threads$ and the \verb|OMP_SCHEDULE| set to dynamic with a 
chunksize of $ 100 $.
The exectution time of the parallel exectution takes $0.052771s$ while the serial computation for the same gridsize of $N=500$ takes $1.387342s$.  
This leaves us with a \verb|speedup ratio| ($speedup = Time_serial / Time_parallel$) of $speedup = 1.387342s/0.052771s = 26.28986 $. 

\begin{figure}
  \includepng[width=\textwidth]{img/ex5/parallel_plot.png}
  \label{ex5parallel}
\end{figure}

To check the correctness of our results, we plot the serial implementation result below which displays the same water simulation result.
\begin{figure}
  \includepng[width=\textwidth]{img/ex5/serial_plot.png}
  \label{ex5serial}
\end{figure}

The code and slurmfile to replicate our results are attached to the repository.
% content end
%###############################################################################

% \printbibliography

\end{document}
